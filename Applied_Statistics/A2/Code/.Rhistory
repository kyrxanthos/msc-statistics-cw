plot(pressure)
print('hello world)
print('hello world')
typeof(trees)
library(margins)
library(margins)
#marginal effects
head(mtcars)
lm4 = lm(mpg ~ disp + hp + wt, data=mtcars)
lm4$coefficients
head(marginal_effects(lm4))
lm5 = lm(mpg ~ disp + hp + wt + disp:hp, data=mtcars)
head(marginal_effects(lm5))
#interaction plots
lm(mpg ~ wt + drat:wt, data = mtcars)
## number of samples
n <- 500
## variables
x1 <- rbinom(n, size = 1, prob = 0.5)
x2 <- runif(n, min = -5, max = 5)
## true intercept and beta values
a <- 0.88
b1 <- 1.5
b2 <- -0.34
b1 <- 1.5
b2 <- -0.34
b3 <- -4
e <- rnorm(n, mean = 0, sd = 5)
## simulate data
y <- a + (b1 * x1) + (b2 * x2) + (b3 * x1 * x2) + e
sim.dat <- data.frame(y, x1, x2)
lm1 <- lm(y ~ x1 * x2, dat = sim.dat)
summary(lm1)
mycoef <- coef(lm1)
sim1 <- sim.dat[sim.dat$x1 == 0, ]
sim2 <- sim.dat[sim.dat$x1 == 1, ]
plot(sim1$x2, sim1$y, pch = 16, xlab = expression(x[2]), ylab = "y")
sim2 <- sim.dat[sim.dat$x1 == 1, ]
plot(sim1$x2, sim1$y, pch = 16, xlab = expression(x[2]), ylab = "y")
abline(a = mycoef[1], b = mycoef[3], lty = 2, lwd = 3, col = "red")
points(sim2$x2, sim2$y, pch = 17, col = "pink")
abline(a = mycoef[1] + mycoef[2], b = mycoef[3] + mycoef[4], lty = 2,lwd = 3, col = "blue")
# interaction plots again
data("ToothGrowth")
head(ToothGrowth)
lmto = lm(len ~ supp * factor(dose), data=ToothGrowth)
summary(lmto)
interaction.plot(ToothGrowth$supp, factor(ToothGrowth$dose), ToothGrowth$len)
interaction.plot(factor(ToothGrowth$dose), ToothGrowth$supp, ToothGrowth$len)
# interaction plots again
data("ToothGrowth")
head(ToothGrowth)
lmto = lm(len ~ supp * factor(dose), data=ToothGrowth)
summary(lmto)
l1 <- lm(len ~ suppVC + factor(dose) + suppVC:factor(dose)2 , data=ToothGrowth)
l1 <- lm(len ~ suppVC + factor(dose) + suppVC:factor(dose) , data=ToothGrowth)
l1 <- lm(len ~ suppVC + factor(dose) + supp:factor(dose) , data=ToothGrowth)
l1 <- lm(len ~ supp + factor(dose) + supp:factor(dose) , data=ToothGrowth)
summary(l1)
l1 <- lm(len ~ supp + factor(dose)  , data=ToothGrowth)
l1
summary(l1)
l1 <- lm(len ~ supp + factor(dose)1 + supp:factor(dose) , data=ToothGrowth)
rm(list=ls())  #clear loadspace
setwd('/Users/lysi2/Documents/UNI_Imperial/Applied_Stats/Problem Sheets/Code')
load('poisson-data.RData')
dat
y <- dat$y
x <- dat$x
beta <- c(20,4) #initial guess
for (i in 1:25){
eta <- cbind(1,x)%*%beta #estimated linear predictor
mu <- exp(eta)  #estimated mean response
z <- eta +((y-mu)/mu) #form the adjusted variate
w <- mu #weights
lmod <- lm(z~x, weights=w) #regress z on x with weights w
beta <- as.numeric(lmod$coeff) #new beta
print(beta) #print out the beta estimate every iteration
}
myglm <- glm(y~x, family=poisson(link="log"))
summary(myglm)
plot(x,y)
xs <- seq(-1,1,by=0.01)
lines(xs, exp(beta[1]+beta[2]*xs), col='red')
X <- cbind(1,x) # design matrix
J <- t(X)%*%diag(as.vector(mu))%*%X # Fishers Info matrix
invJ <- solve(J) # and its inverse
invJ
log(1)
y <- dat$y
x <- dat$x
beta <- c(20,4) #initial guess
for (i in 1:25){
eta <- cbind(1,x)%*%beta #estimated linear predictor
mu <- exp(eta)  #estimated mean response
z <- eta +((y-mu)/mu) #form the adjusted variate
w <- mu #weights
lmod <- lm(z~x, weights=w) #regress z on x with weights w
beta <- as.numeric(lmod$coeff) #new beta
print(beta) #print out the beta estimate every iteration
}
myglm <- glm(y~x, family=poisson(link="log"))
summary(myglm)
plot(x,y)
xs <- seq(-1,1,by=0.01)
lines(xs, exp(beta[1]+beta[2]*xs), col='red')
X <- cbind(1,x) # design matrix
J <- t(X)%*%diag(as.vector(mu))%*%X # Fishers Info matrix
invJ
x
y
x_star <- c(-1,-1,-1,0,0,0,1,1,1)
?predict
x_star <- data.frame(c(-1,-1,-1,0,0,0,1,1,1))
x_star
?data.drame
?data.frame
x_star <- data.frame(x = c(-1,-1,-1,0,0,0,1,1,1))
x_star
x_star <- data.frame(x = c(-1,-1,-1,0,0,0,1,1,1))
predict(myglm, x_star, interval='prediction')
predict(myglm, x_star, interval='response')
predict(myglm, x_star, type='response')
beta
x_star <- c(1,1)
t(x_star)%*%beta
x_star <- data.frame(x = c(1))
predict(myglm, x_star, type='response')
x_star <- data.frame(x = c(1,1))
predict(myglm, x_star, type='response')
x_star <- data.frame(x = c(1,0))
predict(myglm, x_star, type='response')
x_star <- data.frame(x = c(0,0))
predict(myglm, x_star, type='response')
x_star <- data.frame(x = c(2))
predict(myglm, x_star, type='response')
x_star <- data.frame(x = c(0.5))
predict(myglm, x_star, type='response')
x_star <- c(1,1)
t(x_star)%*%beta
dim(x_star)
x_star <- matrix(data = c(1,0), byrow = T, ncol = 2)
x_star
t(x_star)%*%beta
x_star%*%beta
x_star <- matrix(data = c(0,0), byrow = T, ncol = 2)
x_star%*%beta
x_star <- matrix(data = c(1,1), byrow = T, ncol = 2)
x_star%*%beta
x = rep(c(-1,0,1),c(2,4,3))
y = c(2,4,6,7,8,10,11,12,14)
plot(y~x)
M = 5 #Number of iterations
X = cbind(1,x) #Specifying design matrix beta = c(10,5) #Initial guess
for (i in 1:M){
eta = X%*%beta #Estimated linear predictor mu = eta #Estimated mean response
z = y #Form the adjusted variate
w = 1/mu #weights
lmz = lm(z~x, weights=w) #regress z on x with weights w beta = lmz$coefficients #new beta
print(beta) #print out the beta estimate every iteration
}
plot(y~x)
abline(beta)
x = rep(c(-1,0,1),c(2,4,3))
y = c(2,4,6,7,8,10,11,12,14)
plot(y~x)
M = 5 #Number of iterations
X = cbind(1,x) #Specifying design matrix beta = c(10,5) #Initial guess
for (i in 1:M){
eta = X%*%beta #Estimated linear predictor
mu = eta #Estimated mean response
z = y #Form the adjusted variate
w = 1/mu #weights
lmz = lm(z~x, weights=w) #regress z on x with weights w
beta = lmz$coefficients #new beta
print(beta) #print out the beta estimate every iteration
}
plot(y~x)
abline(beta)
J= t(X)%*%diag(1/as.numeric(mu))%*%X # Fisher information matrix
invJ = solve(J) # and its inverse
sqrt(diag(invJ))
summary(glm(y~x,family=poisson(link="identity")))
plot(y~x)
abline(beta)
points(c(0.2,8),col='red')
points(c(0.2,8),col='red')
?points
points(x= 0.25, y= 8,col='red')
y_star <- x_star*beta
y_star
y_star <- t(x_star)*beta
y_star
beta
typeof(beta)
xs[1] <- 1
xs
x_star = c(1,0.25)
y_star <- t(x_star)*beta
y_star
x_star
t(x_star)
t(t(x_star))
typeof(t(t(x_star)))
x_star <- matrix(data = c(1,0.25), byrow = T, ncol = 2)
typeof(x_star)
y_star <- t(x_star)*beta
y_star
x_star
x_star <- matrix(data = c(1,0.25), byrow = T, nrow = 2)
x_star
y_star <- t(x_star)*beta
y_star
t(x_star)
beta
x_star <- matrix(data = c(1,0.25), byrow = T, nrow = 2)
x_star
y_star <- t(x_star)*beta
y_star
y_star <- t(x_star)%*%beta
y_star
w
diag(w)
x = rep(c(-1,0,1),c(2,4,3))
y = c(2,4,6,7,8,10,11,12,14)
plot(y~x)
M = 5 #Number of iterations
X = cbind(1,x) #Specifying design matrix beta = c(10,5) #Initial guess
for (i in 1:M){
eta = X%*%beta #Estimated linear predictor
mu = eta #Estimated mean response
z = y #Form the adjusted variate
w = 1/mu #weights
lmz = lm(z~x, weights=w) #regress z on x with weights w
beta = lmz$coefficients #new beta
print(beta) #print out the beta estimate every iteration
}
plot(y~x)
abline(beta)
J= t(X)%*%diag(1/as.numeric(mu))%*%X # Fisher information matrix
invJ = solve(J) # and its inverse
sqrt(diag(invJ))
summary(glm(y~x,family=poisson(link="identity")))
for (i in 1:M){
eta = X%*%beta #Estimated linear predictor
mu = eta #Estimated mean response
z = y #Form the adjusted variate
w = 1/mu #weights
lmz = lm(z~x, weights=w) #regress z on x with weights w
beta = lmz$coefficients #new beta
print(beta) #print out the beta estimate every iteration
}
J= t(X)%*%diag(1/as.numeric(mu))%*%X # Fisher information matrix
invJ = solve(J) # and its inverse
sqrt(diag(invJ))
summary(glm(y~x,family=poisson(link="identity")))
plot(y~x)
abline(beta)
points(x= 0.25, y= 8,col='red')
myglm <- glm(y~x,family=poisson(link="identity"))
summary(myglm)
plot(y~x)
abline(beta)
points(x= 0.25, y= 8,col='red')
x_star = c(1,0.25)
x_star <- matrix(data = c(1,0.25), byrow = T, nrow = 2)
y_star <- t(x_star)%*%beta
predict(myglm, data.frame(x=x_star))
y_star
qnorm(0.96)
qnorm(0.95)
pnorm(0.95)
pnorm(0.05)
sqrt(diag(invJ))
cov_beta <- sqrt(diag(invJ))
qnorm(0.025)
(1-0.95)/2
z_alpha <- function(alpha) c(qnorm((1-alpha)/2), -qnorm((1-alpha)/2))
z_alpha(0.05)
z_alpha(0.005)
1-0.05
z_alpha <- function(alpha) c(qnorm((alpha)/2), -qnorm((alpha)/2))
z_alpha(0.05)
eta_star - z_alpha(0.05)[1]*sqrt(t(x_star)%*%cov_beta%*%x_star)
eta_star <- t(x_star)%*%beta
eta_star - z_alpha(0.05)[1]*sqrt(t(x_star)%*%cov_beta%*%x_star)
t(x_star)%*%cov_beta
x_star
dim(x_star)
dim(cov_beta)
cov_beta <- sqrt(diag(invJ))
cov_beta
cov_beta1 <- matrix(data = c(cov_beta[1],cov_beta[2]), byrow = T, nrow = 2)
dim(cov_beta)
dim(cov_beta1)
solve(cov_beta)
x = rep(c(-1,0,1),c(2,4,3))
y = c(2,4,6,7,8,10,11,12,14)
plot(y~x)
M = 5 #Number of iterations
X = cbind(1,x) #Specifying design matrix beta = c(10,5) #Initial guess
for (i in 1:M){
eta = X%*%beta #Estimated linear predictor
mu = eta #Estimated mean response
z = y #Form the adjusted variate
w = 1/mu #weights
lmz = lm(z~x, weights=w) #regress z on x with weights w
beta = lmz$coefficients #new beta
print(beta) #print out the beta estimate every iteration
}
J= t(X)%*%diag(1/as.numeric(mu))%*%X # Fisher information matrix
invJ = solve(J) # and its inverse
cov_beta <- sqrt(diag(invJ))
cov_beta
invJ
eta_star - z_alpha(0.05)[1]*sqrt(t(x_star)%*%invJ%*%x_star)
eta_star - z_alpha(0.05)[2]*sqrt(t(x_star)%*%invJ%*%x_star)
c(eta_star - z_alpha(0.05)*sqrt(t(x_star)%*%invJ%*%x_star))
eta_star - z_alpha(0.05)*sqrt(t(x_star)%*%invJ%*%x_star)
c(eta_star - z_alpha(0.05)*sqrt(t(x_star)%*%invJ%*%x_star))
as.vector(eta_star - z_alpha(0.05)*sqrt(t(x_star)%*%invJ%*%x_star))
eta_star - c(z_alpha(0.05)*sqrt(t(x_star)%*%invJ%*%x_star))
z_alpha(0.05)
CI <-c(eta_star + z_alpha(0.05)[1]*sqrt(t(x_star)%*%invJ%*%x_star),
eta_star + z_alpha(0.05)[2]*sqrt(t(x_star)%*%invJ%*%x_star))
CI
confint(eta_star_R)
eta_star_R <- predict(myglm, data.frame(x=x_star))
confint(eta_star_R)
rm(list=ls())  #clear load space
x
setwd('/Users/lysi2/Documents/UNI_Imperial/Applied_Stats/Assignments/A2/Code')
library(tidyverse)
library(faraway)
library('MASS')
library(car)
library(margins)
#Multicollinearity
data("longley")
head(longley)
mylm1 <- lm(Employed ~ .,data=longley)
vif(mylm1)
#very large
vif(mylm1)
cor(longley$GNP.deflator, longley$Population) #high correlation
data(savings)
head(savings)
mylm <- lm(sr ~ pop15 + pop75 + dpi + ddpi, data = savings)
#output: log likelihood for boxcox transformations
bc <- boxcox(mylm, plotit = TRUE)
boxcox(mylm, plotit = TRUE, lambda = seq(0.5, 1.5, by = 0.1))
#we roughly see where the lamdba corresponding to max likelihood is
lambda <- bc$x
lik <- bc$y
together <- cbind(lambda, lik)
max_lam <- together[order(-lik),][1]
#and now fit a new linear model with a value close to the new lambda
#eg. lamda = 1/3
my_new_lm <- lm(sr^1/3 ~ pop15 + pop75 + dpi + ddpi, data = savings)
#marginal effects
head(mtcars)
lm4 = lm(mpg ~ disp + hp + wt, data=mtcars)
lm4$coefficients
head(marginal_effects(lm4))
lm5 = lm(mpg ~ disp + hp + wt + disp:hp, data=mtcars)
head(marginal_effects(lm5))
#dummy-encoding
data(Prestige)
head(Prestige)
contrasts(Prestige$type) <- "contr.sum"
contrasts(Prestige$type) <- "contr.helmert"
contrasts(Prestige$type) <- "contr.treatment"
lm.treatment <- lm(prestige ~ type, data = Prestige)
contrasts(Prestige$type) <- "contr.sum"
lm.sum <- lm(prestige ~ type, data = Prestige)
contrasts(Prestige$type) <- "contr.helmert"
lm.helmert <- lm(prestige ~ type, data = Prestige)
#one factor models
data(coagulation); head(coagulation)
plot(coag ~ diet, data = coagulation, ylab = "coag time")
with(coagulation, stripchart(coag ~ diet,
vertical = TRUE, method = "stack",xlab = "diet", ylab = "coag time"))
mylm <- lm(coag ~ diet, data = coagulation)
summary(mylm)
mylm2 <- lm(coag ~ diet - 1, data = coagulation)
summary(mylm2)
modnull <- lm(coag ~ 1, data = coagulation)
anova(modnull,mylm2)
#interaction plots
lm(mpg ~ wt + drat:wt, data = mtcars)
## number of samples
n <- 500
## variables
x1 <- rbinom(n, size = 1, prob = 0.5)
x2 <- runif(n, min = -5, max = 5)
## true intercept and beta values
a <- 0.88
b1 <- 1.5
b2 <- -0.34
b3 <- -4
e <- rnorm(n, mean = 0, sd = 5)
## simulate data
y <- a + (b1 * x1) + (b2 * x2) + (b3 * x1 * x2) + e
sim.dat <- data.frame(y, x1, x2)
lm1 <- lm(y ~ x1 * x2, dat = sim.dat)
summary(lm1)
mycoef <- coef(lm1)
sim1 <- sim.dat[sim.dat$x1 == 0, ]
sim2 <- sim.dat[sim.dat$x1 == 1, ]
plot(sim1$x2, sim1$y, pch = 16, xlab = expression(x[2]), ylab = "y")
abline(a = mycoef[1], b = mycoef[3], lty = 2, lwd = 3, col = "red")
points(sim2$x2, sim2$y, pch = 17, col = "pink")
abline(a = mycoef[1] + mycoef[2], b = mycoef[3] + mycoef[4], lty = 2,lwd = 3, col = "blue")
lm2 <- lm(y ~ x1:x2, data = sim.dat)
summary(lm2)
plot(sim1$x2, sim1$y, pch = 16, xlab = expression(x[2]), ylab = "y")
points(sim2$x2, sim2$y, pch = 17, col = "pink")
abline(a = coef(lm2)[1], b = coef(lm2)[2], lwd = 2)
e <- rnorm(n, mean = 0, sd = 0.5)
y <- a + (b1 * x1) + (b2 * x2) + e
sim.dat2 <- data.frame(y, x1, x2)
lm3 <- lm(y ~ x1 * x2, dat = sim.dat2); summary(lm3)
# interaction plots again
data("ToothGrowth")
head(ToothGrowth)
lmto = lm(len ~ supp * factor(dose), data=ToothGrowth)
summary(lmto)
# the lines are not parallel, indicating the potential presence of an interaction effect.
interaction.plot(ToothGrowth$supp, factor(ToothGrowth$dose), ToothGrowth$len)
interaction.plot(factor(ToothGrowth$dose), ToothGrowth$supp, ToothGrowth$len)
l1 <- lm(len ~ supp + factor(dose)1 + supp:factor(dose) , data=ToothGrowth)
x = rep(c(-1,0,1),c(2,4,3))
y = c(2,4,6,7,8,10,11,12,14)
plot(y~x)
M = 5 #Number of iterations
X = cbind(1,x) #Specifying design matrix beta = c(10,5) #Initial guess
for (i in 1:M){
eta = X%*%beta #Estimated linear predictor
mu = eta #Estimated mean response
z = y #Form the adjusted variate
w = 1/mu #weights
lmz = lm(z~x, weights=w) #regress z on x with weights w
beta = lmz$coefficients #new beta
print(beta) #print out the beta estimate every iteration
}
J= t(X)%*%diag(1/as.numeric(mu))%*%X # Fisher information matrix
# this is cov(beta)
invJ = solve(J)
#standard error
sqrt(diag(invJ))
#now using glm function
myglm <- glm(y~x,family=poisson(link="identity"))
summary(myglm)
plot(y~x)
abline(beta)
points(x= 0.25, y= 8,col='red')
x_star <- matrix(data = c(1,0.25), byrow = T, nrow = 2)
l1 <- lm(len ~ supp + factor(dose) + supp:factor(dose) , data=ToothGrowth)
x = rep(c(-1,0,1),c(2,4,3))
y = c(2,4,6,7,8,10,11,12,14)
plot(y~x)
M = 5 #Number of iterations
X = cbind(1,x) #Specifying design matrix beta = c(10,5) #Initial guess
for (i in 1:M){
eta = X%*%beta #Estimated linear predictor
mu = eta #Estimated mean response
z = y #Form the adjusted variate
w = 1/mu #weights
lmz = lm(z~x, weights=w) #regress z on x with weights w
beta = lmz$coefficients #new beta
print(beta) #print out the beta estimate every iteration
}
M = 5 #Number of iterations
X = cbind(1,x) #Specifying design matrix
beta = c(10,5) #Initial guess
for (i in 1:M){
eta = X%*%beta #Estimated linear predictor
mu = eta #Estimated mean response
z = y #Form the adjusted variate
w = 1/mu #weights
lmz = lm(z~x, weights=w) #regress z on x with weights w
beta = lmz$coefficients #new beta
print(beta) #print out the beta estimate every iteration
}
J= t(X)%*%diag(1/as.numeric(mu))%*%X # Fisher information matrix
# this is cov(beta)
invJ = solve(J)
#standard error
sqrt(diag(invJ))
#now using glm function
myglm <- glm(y~x,family=poisson(link="identity"))
summary(myglm)
plot(y~x)
abline(beta)
points(x= 0.25, y= 8,col='red')
x_star <- matrix(data = c(1,0.25), byrow = T, nrow = 2)
eta_star <- t(x_star)%*%beta
eta_star_R <- predict(myglm, data.frame(x=x_star))
z_alpha <- function(alpha) c(qnorm((alpha)/2), -qnorm((alpha)/2))
eta_star - c(z_alpha(0.05)*sqrt(t(x_star)%*%invJ%*%x_star))
z_alpha <- function(alpha) c(qnorm((alpha)/2), -qnorm((alpha)/2))
#careful, if link function is not identity you need to transform.
CI <-c(eta_star + z_alpha(0.05)[1]*sqrt(t(x_star)%*%invJ%*%x_star),
eta_star + z_alpha(0.05)[2]*sqrt(t(x_star)%*%invJ%*%x_star))
CI
source("~/Documents/UNI_Imperial/Applied_Stats/Assignments/A2/Code/practise.R", echo=TRUE)
fig.width = 7
fig.height = 5
plot(sim1$x2, sim1$y, pch = 16, xlab = expression(x[2]), ylab = "y")
points(sim2$x2, sim2$y, pch = 17, col = "pink")
abline(a = coef(lm2)[1], b = coef(lm2)[2], lwd = 2)
rm(list=ls())  #clear load space
